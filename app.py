import streamlit as st
import os
from datetime import datetime, timedelta
import json
from pathlib import Path
import requests
import re

# Page config
st.set_page_config(
    page_title="ì €í‰ê°€ ìš°ëŸ‰ì£¼ ë¶„ì„ê¸°",
    page_icon="ğŸ“Š",
    layout="wide"
)

# Initialize data directory
DATA_DIR = Path("analysis_data")
DATA_DIR.mkdir(exist_ok=True)
ANALYSIS_FILE = DATA_DIR / "analyses.json"

# Get API key from Streamlit secrets or environment variable
def get_api_key():
    try:
        api_key = st.secrets["PERPLEXITY_API_KEY"]
        return api_key
    except Exception as e:
        api_key = os.getenv("PERPLEXITY_API_KEY")
        if not api_key:
            st.error("âš ï¸ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
            st.stop()
        return api_key

# Load existing analyses
def load_analyses():
    if ANALYSIS_FILE.exists():
        with open(ANALYSIS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

# Save analyses
def save_analyses(analyses):
    with open(ANALYSIS_FILE, 'w', encoding='utf-8') as f:
        json.dump(analyses, f, ensure_ascii=False, indent=2)

# Detect if Korean stock based on input
def is_korean_stock(ticker_or_name):
    """Detect if the input is likely a Korean stock"""
    # Check for Korean characters
    if re.search(r'[\uac00-\ud7a3]', ticker_or_name):
        return True
    # Check for 6-digit Korean stock code
    if re.match(r'^\d{6}$', ticker_or_name.strip()):
        return True
    # Known Korean stock tickers
    korean_tickers = ['005930', '086790', '000660', '035420', '051910', '105560', '055550', '035720', '096770']
    if ticker_or_name.strip() in korean_tickers:
        return True
    return False

# Perplexity API call with ULTRA STRICT prompt
def analyze_stock_with_perplexity(ticker_or_name, api_key):
    url = "https://api.perplexity.ai/chat/completions"
    
    # Detect if Korean stock for customized prompt
    is_korean = is_korean_stock(ticker_or_name)
    
    # Korean-specific instructions
    korean_instructions = """
**í•œêµ­ ì£¼ì‹ íŠ¹ë³„ ì§€ì¹¨:**
- PRIMARY SOURCE: ë„¤ì´ë²„ ê¸ˆìœµ (finance.naver.com) - í•„ìˆ˜ ìš°ì„  ê²€ìƒ‰
- KRX (í•œêµ­ê±°ë˜ì†Œ) ë°ì´í„° í™œìš©
- ê¸°ì—… IR í˜ì´ì§€ í™•ì¸
- í•œêµ­ ê¸ˆìœµì£¼ (í•˜ë‚˜ê¸ˆìœµì§€ì£¼, ê¸°ì—…ì€í–‰, KBê¸ˆìœµ ë“±)ëŠ” 2023ë…„ë¶€í„° ë¶„ê¸° ë°°ë‹¹ ì‹¤ì‹œ ì¤‘
- í•œêµ­ì–´ë¡œ "í•˜ë‚˜ê¸ˆìœµì§€ì£¼ ë¶„ê¸°ë°°ë‹¹" ê²€ìƒ‰ í•„ìˆ˜
- ì˜ˆì‹œ: í•˜ë‚˜ê¸ˆìœµì§€ì£¼ëŠ” 2023ë…„ë¶€í„° ë¶„ê¸°ë³„ ë°°ë‹¹ (906ì› x 4íšŒ)
""" if is_korean else ""
    
    # ULTRA STRICT prompt
    prompt = f"""
You are an elite financial analyst. Analyze '{ticker_or_name}' with MAXIMUM PRECISION.

{korean_instructions}

**ULTRA STRICT RULES - VIOLATION IS UNACCEPTABLE:**

1. **ALL DATA MUST BE FOUND:**
   - For ANY publicly traded company, P/E and P/B ratios ALWAYS exist
   - For dividend-paying companies, dividend frequency (quarterly/annual) ALWAYS exists
   - Saying "not available", "not specified", or "N/A" for basic metrics is FORBIDDEN

2. **MANDATORY DATA SOURCES:**
   {'- **KOREAN STOCKS**: Naver Finance (finance.naver.com) - USE THIS FIRST!' if is_korean else ''}
   - Yahoo Finance (finance.yahoo.com) - PRIMARY for non-Korean stocks
   - Google Finance - Secondary source
   - Investing.com - Alternative source
   - Company official IR page - For corporate actions

3. **SPECIFIC SEARCH INSTRUCTIONS:**
   - P/E Ratio: {'Search on Naver Finance first' if is_korean else 'Search on Yahoo Finance'}
   - P/B Ratio: {'Check Naver Finance ì£¼ìš”ì¬ë¬´ì •ë³´' if is_korean else 'Yahoo Finance or Investing.com'}
   - Dividend Frequency: {'Search "ë¶„ê¸°ë°°ë‹¹" or check company IR' if is_korean else 'Check company IR or dividend sites'}
   - {'**CRITICAL**: Korean financial stocks (banks, insurance) often pay QUARTERLY dividends since 2023!' if is_korean else ''}

4. **REAL EXAMPLES:**
   {'- í•˜ë‚˜ê¸ˆìœµì§€ì£¼: Quarterly dividend (906ì› x 4), 4.81% yield' if is_korean else ''}
   {'- ì‚¼ì„±ì „ì: Semi-annual dividend, check Naver Finance' if is_korean else ''}
   - Pfizer: Quarterly dividend ($0.43 x 4), 6.51% yield, P/B ~1.8-1.9

5. **ZERO TOLERANCE POLICY:**
   - "Data not available" = FAILURE
   - "Not specified" for dividend frequency = UNACCEPTABLE
   - Empty P/E, P/B values = REJECTION

**Required Data Points:**

1. **Trailing P/E Ratio**: {'Naver Finance or' if is_korean else ''} Yahoo Finance, Investing.com
2. **Price-to-Book Ratio (P/B)**: {'Naver Finance ì£¼ìš”ì¬ë¬´ì •ë³´ or' if is_korean else ''} Financial sites
3. **Dividend Yield**: Percentage from major sites
4. **Dividend Frequency**: Quarterly/Semi-annual/Annual - MUST specify
5. **Dividend History**: 10-year track record
6. **Share Buybacks**: Recent announcements
7. **Treasury Stock**: Company balance sheet

**Scoring Criteria:**

1. Trailing PER: Below 5: 20pts | 5-8: 15pts | 8-10: 10pts | Above 10: 5pts
2. PBR: Below 0.3: 5pts | 0.3-0.6: 4pts | 0.6-1.0: 3pts | Above 1.0: 0pts
3. Profit Sustainability: Sustainable: 5pts | Unstable: 0pts
4. Duplicate Listing: No: 5pts | Yes: 0pts
5. Dividend Yield: Above 7%: 10pts | 5-7%: 7pts | 3-5%: 5pts | Below 3%: 2pts | None: 0pts
6. Quarterly Dividends: Yes: 5pts | No: 0pts
7. Dividend Increases: 10+yrs: 5pts | 5+yrs: 4pts | 3+yrs: 3pts | None: 0pts
8. Regular Buybacks: Yes: 7pts | No: 0pts
9. Buyback Ratio: Above 2%: 8pts | 1.5-2%: 5pts | 0.5-1.5%: 3pts | Below: 0pts
10. Treasury Stock: None: 5pts | Below 2%: 4pts | 2-5%: 2pts | Above 5%: 0pts
11. Growth Potential: Very High: 10pts | High: 7pts | Medium: 5pts | Low: 3pts
12. Management: Excellent: 10pts | Professional: 5pts | Poor: 0pts
13. Global Brand: Yes: 5pts | No: 0pts

**JSON FORMAT ONLY:**

{{
  "company_name": "Official name",
  "ticker": "Symbol",
  "scores": {{
    "1_trailing_per": {{"value": "15.42 (Yahoo Finance)", "score": 5, "reason": "Source: [specific site]"}},
    "2_pbr": {{"value": "1.88 (Investing.com)", "score": 0, "reason": "Source: [site]"}},
    "3_profit_sustainability": {{"score": 5, "reason": "Business stability"}},
    "4_duplicate_listing": {{"score": 5, "reason": "No subsidiaries listed"}},
    "5_dividend_yield": {{"value": "6.51% (Yahoo Finance)", "score": 7, "reason": "Source: [site]"}},
    "6_quarterly_dividend": {{"score": 5, "reason": "Pays quarterly - Source: [site]"}},
    "7_dividend_increase_years": {{"value": "15 years", "score": 5, "reason": "History from [source]"}},
    "8_buyback_cancellation": {{"score": 7, "reason": "Active program"}},
    "9_cancellation_ratio": {{"value": "1.2%", "score": 3, "reason": "Data from [source]"}},
    "10_treasury_stock": {{"value": "1.5%", "score": 4, "reason": "Balance sheet"}},
    "11_growth_potential": {{"score": 7, "reason": "Growth analysis"}},
    "12_management": {{"score": 10, "reason": "Leadership quality"}},
    "13_global_brand": {{"score": 5, "reason": "Brand recognition"}}
  }},
  "total_score": 78,
  "analysis_summary": "3-4 sentence comprehensive evaluation with key investment thesis."
}}

**FINAL WARNING:**
For major stocks, saying "not available" for P/E, P/B, or dividend frequency = FAILURE.
{'For Korean stocks, CHECK NAVER FINANCE FIRST - it has the most accurate Korean stock data!' if is_korean else ''}

Return ONLY the JSON object.
"""
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # Customize domain filter based on stock type
    domain_filter = [
        "finance.naver.com",  # Korean stocks priority
        "finance.yahoo.com",
        "investing.com",
        "marketwatch.com",
        "seekingalpha.com",
        "gurufocus.com"
    ] if is_korean else [
        "finance.yahoo.com",
        "investing.com",
        "marketwatch.com",
        "seekingalpha.com",
        "gurufocus.com",
        "finance.naver.com"  # Still included but lower priority
    ]
    
    # Use sonar-pro model with maximum settings
    data = {
        "model": "sonar-pro",
        "messages": [
            {"role": "system", "content": f"You are an elite financial analyst. {'For Korean stocks, you ALWAYS check Naver Finance (finance.naver.com) FIRST. Korean financial companies often pay quarterly dividends since 2023.' if is_korean else ''} You NEVER fail to find P/E, P/B, and dividend data for publicly traded companies. You cite specific sources."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.0,
        "max_tokens": 8000,
        "search_domain_filter": domain_filter,
        "return_citations": True,
        "search_recency_filter": "month"
    }
    
    try:
        response = requests.post(url, json=data, headers=headers, timeout=180)
        
        if response.status_code != 200:
            error_detail = f"Status: {response.status_code}"
            try:
                error_json = response.json()
                error_detail += f"\n{json.dumps(error_json, indent=2)}"
            except:
                error_detail += f"\n{response.text}"
            
            st.error(f"âŒ API ìš”ì²­ ì‹¤íŒ¨")
            with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ë‚´ìš© ë³´ê¸°"):
                st.code(error_detail)
            return None
        
        result = response.json()
        content = result['choices'][0]['message']['content']
        
        # Try to parse JSON from the content
        try:
            analysis_data = json.loads(content)
            return analysis_data
        except:
            json_match = re.search(r'```(?:json)?\s*({[\s\S]*?})\s*```', content)
            if json_match:
                analysis_data = json.loads(json_match.group(1))
                return analysis_data
            
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                analysis_data = json.loads(json_match.group())
                return analysis_data
            
            st.error("âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
            with st.expander("ğŸ” AI ì‘ë‹µ ë‚´ìš© ë³´ê¸°"):
                st.code(content)
            return None
            
    except requests.exceptions.Timeout:
        st.error("â±ï¸ ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (180ì´ˆ). ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"ğŸŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}")
        return None
    except Exception as e:
        st.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ë¡œê·¸"):
            st.code(traceback.format_exc())
        return None

# Main app
st.title("ğŸ“Š ì €í‰ê°€ ìš°ëŸ‰ì£¼ ìë™ ë¶„ì„ê¸°")
st.markdown("---")

# Get API key
API_KEY = get_api_key()

# Main content
tab1, tab2 = st.tabs(["ğŸ“ˆ ì¢…ëª© ë¶„ì„", "ğŸ† ì „ì²´ ë­í‚¹"])

with tab1:
    st.header("ì¢…ëª© ë¶„ì„")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        ticker_input = st.text_input("ì¢…ëª©ëª… ë˜ëŠ” í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì, 005930, AAPL, Pfizer, í•˜ë‚˜ê¸ˆìœµì§€ì£¼")
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        analyze_btn = st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)
    
    if analyze_btn and ticker_input:
        # Load existing analyses
        analyses = load_analyses()
        
        # Check if analysis exists and is recent
        ticker_key = ticker_input.strip().upper()
        existing = analyses.get(ticker_key)
        
        analysis_result = None
        
        if existing:
            last_analysis_date = datetime.fromisoformat(existing['timestamp'])
            days_old = (datetime.now() - last_analysis_date).days
            
            if days_old < 7:
                st.info(f"ğŸ“‹ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì‚¬ìš© (ë¶„ì„ì¼: {last_analysis_date.strftime('%Y-%m-%d %H:%M')})")
                analysis_result = existing['data']
            else:
                st.warning(f"ğŸ”„ ë§ˆì§€ë§‰ ë¶„ì„ì´ {days_old}ì¼ ì „ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                with st.spinner('ğŸ¤– ìµœê³  ì„±ëŠ¥ AIë¡œ ì‹¤ì œ ì¬ë¬´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 60-120ì´ˆ ì†Œìš”)'):
                    analysis_result = analyze_stock_with_perplexity(ticker_input, API_KEY)
                    
                    if analysis_result:
                        analyses[ticker_key] = {
                            'timestamp': datetime.now().isoformat(),
                            'data': analysis_result
                        }
                        save_analyses(analyses)
                        st.success("âœ… ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë¨")
        else:
            with st.spinner('ğŸ¤– ìµœê³  ì„±ëŠ¥ AIë¡œ ì‹¤ì œ ì¬ë¬´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 60-120ì´ˆ ì†Œìš”)'):
                analysis_result = analyze_stock_with_perplexity(ticker_input, API_KEY)
                
                if analysis_result:
                    analyses[ticker_key] = {
                        'timestamp': datetime.now().isoformat(),
                        'data': analysis_result
                    }
                    save_analyses(analyses)
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë¨")
        
        # Display results
        if analysis_result:
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ: {analysis_result.get('company_name', ticker_input)}")
            
            # Total score display
            st.markdown("---")
            col1, col2, col3 = st.columns(3)
            with col2:
                st.metric("ì´ì ", f"{analysis_result['total_score']}ì ", "/100ì ")
            
            # Summary
            st.markdown("### ğŸ“ ì¢…í•© í‰ê°€")
            st.info(analysis_result.get('analysis_summary', 'ì¢…í•© í‰ê°€ ì—†ìŒ'))
            
            # Detailed scores
            st.markdown("### ğŸ“Š ì„¸ë¶€ ì ìˆ˜")
            
            scores = analysis_result.get('scores', {})
            
            criteria = [
                ("1. Trailing PER", "1_trailing_per", 20),
                ("2. ì§ì „ ë¶„ê¸° PBR", "2_pbr", 5),
                ("3. ì´ìµ ì§€ì† ê°€ëŠ¥ì„±", "3_profit_sustainability", 5),
                ("4. ì¤‘ë³µ ìƒì¥ ì—¬ë¶€", "4_duplicate_listing", 5),
                ("5. ë°°ë‹¹ìˆ˜ìµë¥ ", "5_dividend_yield", 10),
                ("6. ë¶„ê¸° ë°°ë‹¹ ì‹¤ì‹œ", "6_quarterly_dividend", 5),
                ("7. ë°°ë‹¹ ì—°ì† ì¸ìƒ ì—°ìˆ˜", "7_dividend_increase_years", 5),
                ("8. ìì‚¬ì£¼ ë§¤ì… ë° ì†Œê°", "8_buyback_cancellation", 7),
                ("9. ì—°ê°„ ì†Œê° ë¹„ìœ¨", "9_cancellation_ratio", 8),
                ("10. ìì‚¬ì£¼ ë³´ìœ  ë¹„ìœ¨", "10_treasury_stock", 5),
                ("11. ë¯¸ë˜ ì„±ì¥ ì ì¬ë ¥", "11_growth_potential", 10),
                ("12. ê¸°ì—… ê²½ì˜", "12_management", 10),
                ("13. ì„¸ê³„ì  ë¸Œëœë“œ", "13_global_brand", 5)
            ]
            
            for title, key, max_score in criteria:
                if key in scores:
                    item = scores[key]
                    score = item.get('score', 0)
                    reason = item.get('reason', '')
                    value = item.get('value', '')
                    
                    with st.expander(f"{title}: {score}/{max_score}ì "):
                        if value:
                            st.write(f"**ê°’:** {value}")
                        st.write(f"**í‰ê°€:** {reason}")

with tab2:
    st.header("ğŸ† ì „ì²´ ì¢…ëª© ë­í‚¹")
    
    analyses = load_analyses()
    
    if not analyses:
        st.info("ì•„ì§ ë¶„ì„ëœ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¢…ëª©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”!")
    else:
        # Create ranking list
        ranking_data = []
        for ticker, data in analyses.items():
            analysis = data['data']
            ranking_data.append({
                'ìˆœìœ„': 0,
                'ì¢…ëª©ëª…': analysis.get('company_name', ticker),
                'í‹°ì»¤': analysis.get('ticker', ticker),
                'ì´ì ': analysis.get('total_score', 0),
                'ë¶„ì„ì¼': datetime.fromisoformat(data['timestamp']).strftime('%Y-%m-%d')
            })
        
        # Sort by total score
        ranking_data.sort(key=lambda x: x['ì´ì '], reverse=True)
        
        # Add ranking
        for i, item in enumerate(ranking_data):
            item['ìˆœìœ„'] = i + 1
        
        # Display ranking table
        st.dataframe(
            ranking_data,
            use_container_width=True,
            hide_index=True
        )
        
        # Top 3 highlight
        if len(ranking_data) >= 3:
            st.markdown("---")
            st.subheader("ğŸ¥‡ Top 3 ì¢…ëª©")
            cols = st.columns(3)
            
            for i, col in enumerate(cols[:3]):
                with col:
                    item = ranking_data[i]
                    st.metric(
                        f"#{i+1} {item['ì¢…ëª©ëª…']}",
                        f"{item['ì´ì ']}ì ",
                        f"ë¶„ì„ì¼: {item['ë¶„ì„ì¼']}"
                    )

# Footer
st.markdown("---")
st.caption("âš¡ Powered by Perplexity AI Sonar-Pro | í•œêµ­ ì£¼ì‹ì€ ë„¤ì´ë²„ê¸ˆìœµ ìš°ì„  ê²€ìƒ‰ | ë°ì´í„°ëŠ” ìµœëŒ€ 7ì¼ê°„ ìºì‹œ | ì‹¤ì œ ì¬ë¬´ ë°ì´í„° ê¸°ë°˜ ë¶„ì„")
