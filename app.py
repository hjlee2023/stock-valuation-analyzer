import streamlit as st
import os
from datetime import datetime, timedelta
import json
from pathlib import Path
import requests
import re

# Page config
st.set_page_config(
    page_title="ì €í‰ê°€ ìš°ëŸ‰ì£¼ ë¶„ì„ê¸°",
    page_icon="ğŸ“Š",
    layout="wide"
)

# Initialize data directory
DATA_DIR = Path("analysis_data")
DATA_DIR.mkdir(exist_ok=True)
ANALYSIS_FILE = DATA_DIR / "analyses.json"

# Get API key from Streamlit secrets or environment variable
def get_api_key():
    try:
        api_key = st.secrets["PERPLEXITY_API_KEY"]
        return api_key
    except Exception as e:
        api_key = os.getenv("PERPLEXITY_API_KEY")
        if not api_key:
            st.error("âš ï¸ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
            st.stop()
        return api_key

# Load existing analyses
def load_analyses():
    if ANALYSIS_FILE.exists():
        with open(ANALYSIS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

# Save analyses
def save_analyses(analyses):
    with open(ANALYSIS_FILE, 'w', encoding='utf-8') as f:
        json.dump(analyses, f, ensure_ascii=False, indent=2)

# Validate and recalculate total score
def validate_and_fix_scores(analysis_data):
    """Validate scores and recalculate total if necessary"""
    if not analysis_data or 'scores' not in analysis_data:
        return analysis_data
    
    scores = analysis_data['scores']
    calculated_total = 0
    
    # Score keys and their max values
    score_config = {
        '1_trailing_per': 20,
        '2_pbr': 5,
        '3_profit_sustainability': 5,
        '4_duplicate_listing': 5,
        '5_dividend_yield': 10,
        '6_quarterly_dividend': 5,
        '7_dividend_increase_years': 5,
        '8_buyback_cancellation': 7,
        '9_cancellation_ratio': 8,
        '10_treasury_stock': 5,
        '11_growth_potential': 10,
        '12_management': 10,
        '13_global_brand': 5
    }
    
    # Validate and sum up scores
    for key, max_score in score_config.items():
        if key in scores:
            score_value = scores[key].get('score', 0)
            # Ensure score is within valid range
            if score_value < 0:
                score_value = 0
            elif score_value > max_score:
                score_value = max_score
            
            scores[key]['score'] = score_value
            calculated_total += score_value
    
    # If total_score is wildly incorrect (> 100 or negative), fix it
    if 'total_score' not in analysis_data or analysis_data['total_score'] > 100 or analysis_data['total_score'] < 0:
        analysis_data['total_score'] = calculated_total
        st.warning(f"âš ï¸ ì´ì ì´ ë¹„ì •ìƒì ì´ì–´ì„œ ì¬ê³„ì‚°í–ˆìŠµë‹ˆë‹¤: {calculated_total}ì ")
    
    return analysis_data

# Detect if Korean stock based on input
def is_korean_stock(ticker_or_name):
    """Detect if the input is likely a Korean stock"""
    # Check for Korean characters
    if re.search(r'[\uac00-\ud7a3]', ticker_or_name):
        return True
    # Check for 6-digit Korean stock code
    if re.match(r'^\d{6}$', ticker_or_name.strip()):
        return True
    # Known Korean stock tickers
    korean_tickers = ['005930', '086790', '000660', '035420', '051910', '105560', '055550', '035720', '096770']
    if ticker_or_name.strip() in korean_tickers:
        return True
    return False

# Perplexity API call with ULTRA STRICT prompt
def analyze_stock_with_perplexity(ticker_or_name, api_key):
    url = "https://api.perplexity.ai/chat/completions"
    
    # Detect if Korean stock for customized prompt
    is_korean = is_korean_stock(ticker_or_name)
    
    # Korean-specific instructions
    korean_instructions = """
**í•œêµ­ ì£¼ì‹ íŠ¹ë³„ ì§€ì¹¨:**
- PRIMARY SOURCE: ë„¤ì´ë²„ ê¸ˆìœµ (finance.naver.com) - í•„ìˆ˜ ìš°ì„  ê²€ìƒ‰
- KRX (í•œêµ­ê±°ë˜ì†Œ) ë°ì´í„° í™œìš©
- ê¸°ì—… IR í˜ì´ì§€ í™•ì¸
- í•œêµ­ ê¸ˆìœµì£¼ (í•˜ë‚˜ê¸ˆìœµì§€ì£¼, ê¸°ì—…ì€í–‰, KBê¸ˆìœµ ë“±)ëŠ” 2023ë…„ë¶€í„° ë¶„ê¸° ë°°ë‹¹ ì‹¤ì‹œ ì¤‘
- í•œêµ­ì–´ë¡œ "í•˜ë‚˜ê¸ˆìœµì§€ì£¼ ë¶„ê¸°ë°°ë‹¹" ê²€ìƒ‰ í•„ìˆ˜
- ì˜ˆì‹œ: í•˜ë‚˜ê¸ˆìœµì§€ì£¼ëŠ” 2023ë…„ë¶€í„° ë¶„ê¸°ë³„ ë°°ë‹¹ (906ì› x 4íšŒ)
""" if is_korean else ""
    
    # ULTRA STRICT prompt with EXPLICIT score calculation requirement
    prompt = f"""
You are an elite financial analyst. Analyze '{ticker_or_name}' with MAXIMUM PRECISION.

{korean_instructions}

**ULTRA STRICT RULES:**

1. **ALL DATA MUST BE FOUND** - No "N/A" for basic metrics
2. **MANDATORY SOURCES**: {'Naver Finance (finance.naver.com) FIRST for Korean stocks' if is_korean else 'Yahoo Finance, Investing.com, Google Finance'}
3. **SCORE CALCULATION IS CRITICAL**: You MUST correctly sum all 13 individual scores to get total_score

**Scoring Criteria (MAX 100 POINTS):**

1. Trailing PER (MAX 20): Below 5â†’20pts | 5-8â†’15pts | 8-10â†’10pts | >10â†’5pts
2. PBR (MAX 5): <0.3â†’5pts | 0.3-0.6â†’4pts | 0.6-1.0â†’3pts | >1.0â†’0pts
3. Profit Sustainability (MAX 5): Sustainableâ†’5pts | Unstableâ†’0pts
4. Duplicate Listing (MAX 5): Noâ†’5pts | Yesâ†’0pts
5. Dividend Yield (MAX 10): >7%â†’10pts | 5-7%â†’7pts | 3-5%â†’5pts | <3%â†’2pts | Noneâ†’0pts
6. Quarterly Dividends (MAX 5): Yesâ†’5pts | Noâ†’0pts
7. Dividend Increases (MAX 5): 10+yrsâ†’5pts | 5+yrsâ†’4pts | 3+yrsâ†’3pts | Noneâ†’0pts
8. Regular Buybacks (MAX 7): Yesâ†’7pts | Noâ†’0pts
9. Buyback Ratio (MAX 8): >2%â†’8pts | 1.5-2%â†’5pts | 0.5-1.5%â†’3pts | <0.5%â†’0pts
10. Treasury Stock (MAX 5): Noneâ†’5pts | <2%â†’4pts | 2-5%â†’2pts | >5%â†’0pts
11. Growth Potential (MAX 10): Very Highâ†’10pts | Highâ†’7pts | Mediumâ†’5pts | Lowâ†’3pts
12. Management (MAX 10): Excellentâ†’10pts | Professionalâ†’5pts | Poorâ†’0pts
13. Global Brand (MAX 5): Yesâ†’5pts | Noâ†’0pts

**CRITICAL: SCORE CALCULATION**
total_score = sum of all 13 individual scores (MUST be between 0-100)

**JSON FORMAT - EXACT STRUCTURE:**

{{
  "company_name": "Official company name",
  "ticker": "Stock symbol",
  "scores": {{
    "1_trailing_per": {{"value": "15.42 (Source)", "score": 5, "reason": "Source: Yahoo Finance"}},
    "2_pbr": {{"value": "10.1 (Source)", "score": 0, "reason": "Source: Investing.com"}},
    "3_profit_sustainability": {{"score": 5, "reason": "Strong recurring revenue"}},
    "4_duplicate_listing": {{"score": 5, "reason": "No subsidiaries listed"}},
    "5_dividend_yield": {{"value": "6.5%", "score": 7, "reason": "Source: Yahoo Finance"}},
    "6_quarterly_dividend": {{"score": 5, "reason": "Quarterly payments"}},
    "7_dividend_increase_years": {{"value": "15 years", "score": 5, "reason": "15 consecutive increases"}},
    "8_buyback_cancellation": {{"score": 7, "reason": "Active program"}},
    "9_cancellation_ratio": {{"value": "1.2%", "score": 3, "reason": "Moderate activity"}},
    "10_treasury_stock": {{"value": "1.5%", "score": 4, "reason": "Low holdings"}},
    "11_growth_potential": {{"score": 7, "reason": "Strong pipeline"}},
    "12_management": {{"score": 10, "reason": "Experienced team"}},
    "13_global_brand": {{"score": 5, "reason": "Globally recognized"}}
  }},
  "total_score": 68,
  "analysis_summary": "Comprehensive 3-4 sentence evaluation."
}}

**EXAMPLE CALCULATION:**
If scores are: 5+0+5+5+7+5+5+7+3+4+7+10+5 = 68 points (NOT 1000000000!)

**FINAL CHECKS:**
- Each individual score MUST be â‰¤ its maximum
- total_score MUST equal sum of 13 scores
- total_score MUST be between 0-100
- Include specific data sources for all numerical values

Return ONLY the JSON object.
"""
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # Customize domain filter based on stock type
    domain_filter = [
        "finance.naver.com",
        "finance.yahoo.com",
        "investing.com",
        "marketwatch.com",
        "seekingalpha.com",
        "gurufocus.com"
    ] if is_korean else [
        "finance.yahoo.com",
        "investing.com",
        "marketwatch.com",
        "seekingalpha.com",
        "gurufocus.com",
        "finance.naver.com"
    ]
    
    # Use sonar-pro model
    data = {
        "model": "sonar-pro",
        "messages": [
            {"role": "system", "content": f"You are an elite financial analyst. {'For Korean stocks, check Naver Finance FIRST.' if is_korean else ''} You ALWAYS find real data and CORRECTLY calculate total_score by summing all 13 individual scores. Total must be 0-100."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.0,
        "max_tokens": 8000,
        "search_domain_filter": domain_filter,
        "return_citations": True,
        "search_recency_filter": "month"
    }
    
    try:
        response = requests.post(url, json=data, headers=headers, timeout=180)
        
        if response.status_code != 200:
            error_detail = f"Status: {response.status_code}"
            try:
                error_json = response.json()
                error_detail += f"\n{json.dumps(error_json, indent=2)}"
            except:
                error_detail += f"\n{response.text}"
            
            st.error(f"âŒ API ìš”ì²­ ì‹¤íŒ¨")
            with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ë‚´ìš© ë³´ê¸°"):
                st.code(error_detail)
            return None
        
        result = response.json()
        content = result['choices'][0]['message']['content']
        
        # Try to parse JSON from the content
        analysis_data = None
        try:
            analysis_data = json.loads(content)
        except:
            json_match = re.search(r'```(?:json)?\s*({[\s\S]*?})\s*```', content)
            if json_match:
                analysis_data = json.loads(json_match.group(1))
            else:
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    analysis_data = json.loads(json_match.group())
        
        if not analysis_data:
            st.error("âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
            with st.expander("ğŸ” AI ì‘ë‹µ ë‚´ìš© ë³´ê¸°"):
                st.code(content)
            return None
        
        # CRITICAL: Validate and fix scores
        analysis_data = validate_and_fix_scores(analysis_data)
        
        return analysis_data
            
    except requests.exceptions.Timeout:
        st.error("â±ï¸ ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (180ì´ˆ). ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"ğŸŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}")
        return None
    except Exception as e:
        st.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ë¡œê·¸"):
            st.code(traceback.format_exc())
        return None

# Main app
st.title("ğŸ“Š ì €í‰ê°€ ìš°ëŸ‰ì£¼ ìë™ ë¶„ì„ê¸°")
st.markdown("---")

# Get API key
API_KEY = get_api_key()

# Main content
tab1, tab2 = st.tabs(["ğŸ“ˆ ì¢…ëª© ë¶„ì„", "ğŸ† ì „ì²´ ë­í‚¹"])

with tab1:
    st.header("ì¢…ëª© ë¶„ì„")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        ticker_input = st.text_input("ì¢…ëª©ëª… ë˜ëŠ” í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì, 005930, AAPL, Pfizer, í•˜ë‚˜ê¸ˆìœµì§€ì£¼")
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        analyze_btn = st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)
    
    if analyze_btn and ticker_input:
        # Load existing analyses
        analyses = load_analyses()
        
        # Check if analysis exists and is recent
        ticker_key = ticker_input.strip().upper()
        existing = analyses.get(ticker_key)
        
        analysis_result = None
        
        if existing:
            last_analysis_date = datetime.fromisoformat(existing['timestamp'])
            days_old = (datetime.now() - last_analysis_date).days
            
            if days_old < 7:
                st.info(f"ğŸ“‹ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì‚¬ìš© (ë¶„ì„ì¼: {last_analysis_date.strftime('%Y-%m-%d %H:%M')})")
                analysis_result = existing['data']
                # Re-validate old data
                analysis_result = validate_and_fix_scores(analysis_result)
            else:
                st.warning(f"ğŸ”„ ë§ˆì§€ë§‰ ë¶„ì„ì´ {days_old}ì¼ ì „ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                with st.spinner('ğŸ¤– ìµœê³  ì„±ëŠ¥ AIë¡œ ì‹¤ì œ ì¬ë¬´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 60-120ì´ˆ ì†Œìš”)'):
                    analysis_result = analyze_stock_with_perplexity(ticker_input, API_KEY)
                    
                    if analysis_result:
                        analyses[ticker_key] = {
                            'timestamp': datetime.now().isoformat(),
                            'data': analysis_result
                        }
                        save_analyses(analyses)
                        st.success("âœ… ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë¨")
        else:
            with st.spinner('ğŸ¤– ìµœê³  ì„±ëŠ¥ AIë¡œ ì‹¤ì œ ì¬ë¬´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 60-120ì´ˆ ì†Œìš”)'):
                analysis_result = analyze_stock_with_perplexity(ticker_input, API_KEY)
                
                if analysis_result:
                    analyses[ticker_key] = {
                        'timestamp': datetime.now().isoformat(),
                        'data': analysis_result
                    }
                    save_analyses(analyses)
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë¨")
        
        # Display results
        if analysis_result:
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ: {analysis_result.get('company_name', ticker_input)}")
            
            # Total score display
            st.markdown("---")
            col1, col2, col3 = st.columns(3)
            with col2:
                total = analysis_result.get('total_score', 0)
                st.metric("ì´ì ", f"{total}ì ", "/100ì ")
            
            # Summary
            st.markdown("### ğŸ“ ì¢…í•© í‰ê°€")
            st.info(analysis_result.get('analysis_summary', 'ì¢…í•© í‰ê°€ ì—†ìŒ'))
            
            # Detailed scores
            st.markdown("### ğŸ“Š ì„¸ë¶€ ì ìˆ˜")
            
            scores = analysis_result.get('scores', {})
            
            criteria = [
                ("1. Trailing PER", "1_trailing_per", 20),
                ("2. ì§ì „ ë¶„ê¸° PBR", "2_pbr", 5),
                ("3. ì´ìµ ì§€ì† ê°€ëŠ¥ì„±", "3_profit_sustainability", 5),
                ("4. ì¤‘ë³µ ìƒì¥ ì—¬ë¶€", "4_duplicate_listing", 5),
                ("5. ë°°ë‹¹ìˆ˜ìµë¥ ", "5_dividend_yield", 10),
                ("6. ë¶„ê¸° ë°°ë‹¹ ì‹¤ì‹œ", "6_quarterly_dividend", 5),
                ("7. ë°°ë‹¹ ì—°ì† ì¸ìƒ ì—°ìˆ˜", "7_dividend_increase_years", 5),
                ("8. ìì‚¬ì£¼ ë§¤ì… ë° ì†Œê°", "8_buyback_cancellation", 7),
                ("9. ì—°ê°„ ì†Œê° ë¹„ìœ¨", "9_cancellation_ratio", 8),
                ("10. ìì‚¬ì£¼ ë³´ìœ  ë¹„ìœ¨", "10_treasury_stock", 5),
                ("11. ë¯¸ë˜ ì„±ì¥ ì ì¬ë ¥", "11_growth_potential", 10),
                ("12. ê¸°ì—… ê²½ì˜", "12_management", 10),
                ("13. ì„¸ê³„ì  ë¸Œëœë“œ", "13_global_brand", 5)
            ]
            
            for title, key, max_score in criteria:
                if key in scores:
                    item = scores[key]
                    score = item.get('score', 0)
                    reason = item.get('reason', '')
                    value = item.get('value', '')
                    
                    with st.expander(f"{title}: {score}/{max_score}ì "):
                        if value:
                            st.write(f"**ê°’:** {value}")
                        st.write(f"**í‰ê°€:** {reason}")

with tab2:
    st.header("ğŸ† ì „ì²´ ì¢…ëª© ë­í‚¹")
    
    analyses = load_analyses()
    
    if not analyses:
        st.info("ì•„ì§ ë¶„ì„ëœ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¢…ëª©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”!")
    else:
        # Create ranking list
        ranking_data = []
        for ticker, data in analyses.items():
            analysis = data['data']
            # Validate scores before displaying
            analysis = validate_and_fix_scores(analysis)
            
            ranking_data.append({
                'ìˆœìœ„': 0,
                'ì¢…ëª©ëª…': analysis.get('company_name', ticker),
                'í‹°ì»¤': analysis.get('ticker', ticker),
                'ì´ì ': analysis.get('total_score', 0),
                'ë¶„ì„ì¼': datetime.fromisoformat(data['timestamp']).strftime('%Y-%m-%d')
            })
        
        # Sort by total score
        ranking_data.sort(key=lambda x: x['ì´ì '], reverse=True)
        
        # Add ranking
        for i, item in enumerate(ranking_data):
            item['ìˆœìœ„'] = i + 1
        
        # Display ranking table
        st.dataframe(
            ranking_data,
            use_container_width=True,
            hide_index=True
        )
        
        # Top 3 highlight
        if len(ranking_data) >= 3:
            st.markdown("---")
            st.subheader("ğŸ¥‡ Top 3 ì¢…ëª©")
            cols = st.columns(3)
            
            for i, col in enumerate(cols[:3]):
                with col:
                    item = ranking_data[i]
                    st.metric(
                        f"#{i+1} {item['ì¢…ëª©ëª…']}",
                        f"{item['ì´ì ']}ì ",
                        f"ë¶„ì„ì¼: {item['ë¶„ì„ì¼']}"
                    )

# Footer
st.markdown("---")
st.caption("âš¡ Powered by Perplexity AI Sonar-Pro | ë°ì´í„°ëŠ” ìµœëŒ€ 7ì¼ê°„ ìºì‹œ | ì‹¤ì œ ì¬ë¬´ ë°ì´í„° ê¸°ë°˜ ë¶„ì„")
