import streamlit as st
import os
from datetime import datetime, timedelta
import json
from pathlib import Path
import requests

# Page config
st.set_page_config(
    page_title="ì €í‰ê°€ ìš°ëŸ‰ì£¼ ë¶„ì„ê¸°",
    page_icon="ğŸ“Š",
    layout="wide"
)

# Initialize data directory
DATA_DIR = Path("analysis_data")
DATA_DIR.mkdir(exist_ok=True)
ANALYSIS_FILE = DATA_DIR / "analyses.json"

# Get API key from Streamlit secrets or environment variable
def get_api_key():
    try:
        # Try Streamlit secrets first (for cloud deployment)
        api_key = st.secrets["PERPLEXITY_API_KEY"]
        return api_key
    except Exception as e:
        # Fallback to environment variable (for local development)
        api_key = os.getenv("PERPLEXITY_API_KEY")
        if not api_key:
            st.error("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.info("""
            **ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”:**
            
            Streamlit Cloudì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:
            1. Settings â†’ Secrets
            2. ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:
            ```
            PERPLEXITY_API_KEY = "pplx-your-api-key"
            ```
            """)
            st.stop()
        return api_key

# Load existing analyses
def load_analyses():
    if ANALYSIS_FILE.exists():
        with open(ANALYSIS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

# Save analyses
def save_analyses(analyses):
    with open(ANALYSIS_FILE, 'w', encoding='utf-8') as f:
        json.dump(analyses, f, ensure_ascii=False, indent=2)

# Perplexity API call
def analyze_stock_with_perplexity(ticker_or_name, api_key):
    url = "https://api.perplexity.ai/chat/completions"
    
    prompt = f"""
ë‹¤ìŒ í‰ê°€ ê¸°ì¤€ì— ë”°ë¼ '{ticker_or_name}' ì¢…ëª©ì„ ë¶„ì„í•˜ê³  ì ìˆ˜ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”.

í‰ê°€ í•­ëª©:
1. Trailing PER
   - 5 ë¯¸ë§Œ: 20ì 
   - 5 ì´ìƒ 8 ë¯¸ë§Œ: 15ì 
   - 8 ì´ìƒ 10 ë¯¸ë§Œ: 10ì 
   - 10 ì´ìƒ: 5ì 

2. ì§ì „ ë¶„ê¸° PBR
   - 0.3 ë¯¸ë§Œ: 5ì 
   - 0.3 ì´ìƒ 0.6 ë¯¸ë§Œ: 4ì 
   - 0.6 ì´ìƒ 1.0 ë¯¸ë§Œ: 3ì 
   - 1.0 ì´ìƒ: 0ì 

3. ì´ìµ ì§€ì† ê°€ëŠ¥ì„± (ì •ì„±ì  íŒë‹¨)
   - ëŒ€ì²´ë¡œ ì§€ì† ê°€ëŠ¥: 5ì 
   - ë¶ˆì•ˆì •í•œ ì´ìµ ì°½ì¶œë ¥: 0ì 

4. ì¤‘ë³µ ìƒì¥ ì—¬ë¶€ (ìíšŒì‚¬/ì†ìíšŒì‚¬ ìƒì¥ ì—¬ë¶€)
   - ì¤‘ë³µìƒì¥: 0ì 
   - ë‹¨ë…ìƒì¥: 5ì 

5. ë°°ë‹¹ìˆ˜ìµë¥ 
   - 7% ì´ˆê³¼: 10ì 
   - 5% ì´ˆê³¼ 7% ì´í•˜: 7ì 
   - 3% ì´ˆê³¼ 5% ì´í•˜: 5ì 
   - 3% ì´í•˜: 2ì 

6. ë¶„ê¸° ë°°ë‹¹ ì‹¤ì‹œ ì—¬ë¶€
   - ì˜ˆ: 5ì 
   - ì•„ë‹ˆìš”: 0ì 

7. ë°°ë‹¹ ì—°ì† ì¸ìƒ ì—°ìˆ˜
   - 10ë…„ ì´ìƒ: 5ì 
   - 5ë…„ ì´ìƒ: 4ì 
   - 3ë…„ ì´ìƒ: 3ì 
   - í•´ë‹¹ ì—†ìŒ: 0ì 

8. ì •ê¸°ì  ìì‚¬ì£¼ ë§¤ì… ë° ì†Œê° ì—¬ë¶€ (ì—° 1íšŒ ì´ìƒ)
   - ì˜ˆ: 7ì 
   - ì•„ë‹ˆìš”: 0ì 

9. ì—°ê°„ ìì‚¬ì£¼ ì†Œê° ë¹„ìœ¨ (ì´ì£¼ì‹ìˆ˜ ëŒ€ë¹„)
   - 2% ì´ˆê³¼: 8ì 
   - 1.5% ì´ˆê³¼ 2% ì´í•˜: 5ì 
   - 0.5% ì´ˆê³¼ 1.5% ì´í•˜: 3ì 
   - 0.5% ì´í•˜: 0ì 

10. ìì‚¬ì£¼ ë³´ìœ  ë¹„ìœ¨
    - ì—†ìŒ: 5ì 
    - 2% ë¯¸ë§Œ: 4ì 
    - 2% ì´ìƒ 5% ë¯¸ë§Œ: 2ì 
    - 5% ì´ìƒ: 0ì 

11. ë¯¸ë˜ ì„±ì¥ ì ì¬ë ¥ (ì •ì„±ì  íŒë‹¨)
    - ë§¤ìš° ë†’ë‹¤: 10ì 
    - ë†’ë‹¤: 7ì 
    - ë³´í†µ: 5ì 
    - ë‚®ë‹¤: 3ì 

12. ê¸°ì—… ê²½ì˜ (ê²½ì˜ì í‰ê°€)
    - ìš°ìˆ˜í•œ ê²½ì˜ì: 10ì 
    - ì „ë¬¸ ê²½ì˜ì: 5ì 
    - ì €ì¡°í•œ ì‹¤ì ì˜ ì˜¤ë„ˆ ê²½ì˜: 0ì 

13. ì„¸ê³„ì  ë¸Œëœë“œ ë³´ìœ  ì—¬ë¶€
    - ìˆë‹¤: 5ì 
    - ì—†ë‹¤: 0ì 

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”:
{{
  "company_name": "íšŒì‚¬ëª…",
  "ticker": "í‹°ì»¤",
  "scores": {{
    "1_trailing_per": {{"value": "10.5", "score": 10, "reason": "ê°„ë‹¨í•œ ì„¤ëª…"}},
    "2_pbr": {{"value": "0.8", "score": 3, "reason": "ê°„ë‹¨í•œ ì„¤ëª…"}},
    "3_profit_sustainability": {{"score": 5, "reason": "íŒë‹¨ ê·¼ê±°"}},
    "4_duplicate_listing": {{"score": 5, "reason": "íŒë‹¨ ê·¼ê±°"}},
    "5_dividend_yield": {{"value": "3.5%", "score": 5, "reason": "ê°„ë‹¨í•œ ì„¤ëª…"}},
    "6_quarterly_dividend": {{"score": 0, "reason": "íŒë‹¨ ê·¼ê±°"}},
    "7_dividend_increase_years": {{"value": "5ë…„", "score": 4, "reason": "ê°„ë‹¨í•œ ì„¤ëª…"}},
    "8_buyback_cancellation": {{"score": 7, "reason": "íŒë‹¨ ê·¼ê±°"}},
    "9_cancellation_ratio": {{"value": "1.2%", "score": 3, "reason": "ê°„ë‹¨í•œ ì„¤ëª…"}},
    "10_treasury_stock": {{"value": "1.5%", "score": 4, "reason": "ê°„ë‹¨í•œ ì„¤ëª…"}},
    "11_growth_potential": {{"score": 7, "reason": "íŒë‹¨ ê·¼ê±°"}},
    "12_management": {{"score": 10, "reason": "íŒë‹¨ ê·¼ê±°"}},
    "13_global_brand": {{"score": 5, "reason": "íŒë‹¨ ê·¼ê±°"}}
  }},
  "total_score": 68,
  "analysis_summary": "ì „ì²´ ì¢…í•© í‰ê°€ (3-4ë¬¸ì¥)"
}}
"""
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "llama-3.1-sonar-large-128k-online",
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìµœì‹  ì¬ë¬´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë¶„ì„ì„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.2,
        "max_tokens": 4000
    }
    
    try:
        response = requests.post(url, json=data, headers=headers, timeout=60)
        
        # Detailed error handling
        if response.status_code != 200:
            error_detail = f"Status: {response.status_code}"
            try:
                error_json = response.json()
                error_detail += f"\n{json.dumps(error_json, indent=2)}"
            except:
                error_detail += f"\n{response.text}"
            
            st.error(f"âŒ API ìš”ì²­ ì‹¤íŒ¨")
            with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ë‚´ìš© ë³´ê¸°"):
                st.code(error_detail)
                
                if response.status_code == 401:
                    st.warning("ğŸ”‘ API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Streamlit Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
                elif response.status_code == 400:
                    st.warning("âš ï¸ ìš”ì²­ í˜•ì‹ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            return None
        
        result = response.json()
        
        # Extract JSON from response
        content = result['choices'][0]['message']['content']
        
        # Try to parse JSON from the content
        import re
        
        # First try: direct JSON parse
        try:
            analysis_data = json.loads(content)
            return analysis_data
        except:
            # Second try: extract JSON from markdown code block
            json_match = re.search(r'```(?:json)?\s*({[\s\S]*?})\s*```', content)
            if json_match:
                analysis_data = json.loads(json_match.group(1))
                return analysis_data
            
            # Third try: find any JSON object
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                analysis_data = json.loads(json_match.group())
                return analysis_data
            
            # If all fails, show the raw response
            st.error("âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
            with st.expander("ğŸ” AI ì‘ë‹µ ë‚´ìš© ë³´ê¸°"):
                st.code(content)
            return None
            
    except requests.exceptions.Timeout:
        st.error("â±ï¸ ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (60ì´ˆ). ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"ğŸŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}")
        return None
    except Exception as e:
        st.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ë¡œê·¸"):
            st.code(traceback.format_exc())
        return None

# Main app
st.title("ğŸ“Š ì €í‰ê°€ ìš°ëŸ‰ì£¼ ìë™ ë¶„ì„ê¸°")
st.markdown("---")

# Get API key
API_KEY = get_api_key()

if API_KEY:
    # Show API key status (masked)
    with st.sidebar:
        st.success(f"âœ… API í‚¤ ì„¤ì • ì™„ë£Œ")
        st.caption(f"Key: {API_KEY[:8]}...{API_KEY[-4:]}")

# Main content
tab1, tab2 = st.tabs(["ğŸ“ˆ ì¢…ëª© ë¶„ì„", "ğŸ† ì „ì²´ ë­í‚¹"])

with tab1:
    st.header("ì¢…ëª© ë¶„ì„")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        ticker_input = st.text_input("ì¢…ëª©ëª… ë˜ëŠ” í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì, 005930, AAPL")
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        analyze_btn = st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)
    
    if analyze_btn and ticker_input:
        # Load existing analyses
        analyses = load_analyses()
        
        # Check if analysis exists and is recent
        ticker_key = ticker_input.strip().upper()
        existing = analyses.get(ticker_key)
        
        analysis_result = None
        
        if existing:
            last_analysis_date = datetime.fromisoformat(existing['timestamp'])
            days_old = (datetime.now() - last_analysis_date).days
            
            if days_old < 7:
                st.info(f"ğŸ“‹ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì‚¬ìš© (ë¶„ì„ì¼: {last_analysis_date.strftime('%Y-%m-%d %H:%M')})")
                analysis_result = existing['data']
            else:
                st.warning(f"ğŸ”„ ë§ˆì§€ë§‰ ë¶„ì„ì´ {days_old}ì¼ ì „ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                with st.spinner('ğŸ¤– AIê°€ ì¢…ëª©ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 30-60ì´ˆ ì†Œìš”)'):
                    analysis_result = analyze_stock_with_perplexity(ticker_input, API_KEY)
                    
                    if analysis_result:
                        # Update with new analysis
                        analyses[ticker_key] = {
                            'timestamp': datetime.now().isoformat(),
                            'data': analysis_result
                        }
                        save_analyses(analyses)
                        st.success("âœ… ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë¨")
        else:
            with st.spinner('ğŸ¤– AIê°€ ì¢…ëª©ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 30-60ì´ˆ ì†Œìš”)'):
                analysis_result = analyze_stock_with_perplexity(ticker_input, API_KEY)
                
                if analysis_result:
                    # Save new analysis
                    analyses[ticker_key] = {
                        'timestamp': datetime.now().isoformat(),
                        'data': analysis_result
                    }
                    save_analyses(analyses)
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ë¨")
        
        # Display results
        if analysis_result:
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ: {analysis_result.get('company_name', ticker_input)}")
            
            # Total score display
            st.markdown("---")
            col1, col2, col3 = st.columns(3)
            with col2:
                st.metric("ì´ì ", f"{analysis_result['total_score']}ì ", "/100ì ")
            
            # Summary
            st.markdown("### ğŸ“ ì¢…í•© í‰ê°€")
            st.info(analysis_result.get('analysis_summary', 'ì¢…í•© í‰ê°€ ì—†ìŒ'))
            
            # Detailed scores
            st.markdown("### ğŸ“Š ì„¸ë¶€ ì ìˆ˜")
            
            scores = analysis_result.get('scores', {})
            
            criteria = [
                ("1. Trailing PER", "1_trailing_per", 20),
                ("2. ì§ì „ ë¶„ê¸° PBR", "2_pbr", 5),
                ("3. ì´ìµ ì§€ì† ê°€ëŠ¥ì„±", "3_profit_sustainability", 5),
                ("4. ì¤‘ë³µ ìƒì¥ ì—¬ë¶€", "4_duplicate_listing", 5),
                ("5. ë°°ë‹¹ìˆ˜ìµë¥ ", "5_dividend_yield", 10),
                ("6. ë¶„ê¸° ë°°ë‹¹ ì‹¤ì‹œ", "6_quarterly_dividend", 5),
                ("7. ë°°ë‹¹ ì—°ì† ì¸ìƒ ì—°ìˆ˜", "7_dividend_increase_years", 5),
                ("8. ìì‚¬ì£¼ ë§¤ì… ë° ì†Œê°", "8_buyback_cancellation", 7),
                ("9. ì—°ê°„ ì†Œê° ë¹„ìœ¨", "9_cancellation_ratio", 8),
                ("10. ìì‚¬ì£¼ ë³´ìœ  ë¹„ìœ¨", "10_treasury_stock", 5),
                ("11. ë¯¸ë˜ ì„±ì¥ ì ì¬ë ¥", "11_growth_potential", 10),
                ("12. ê¸°ì—… ê²½ì˜", "12_management", 10),
                ("13. ì„¸ê³„ì  ë¸Œëœë“œ", "13_global_brand", 5)
            ]
            
            for title, key, max_score in criteria:
                if key in scores:
                    item = scores[key]
                    score = item.get('score', 0)
                    reason = item.get('reason', '')
                    value = item.get('value', '')
                    
                    with st.expander(f"{title}: {score}/{max_score}ì "):
                        if value:
                            st.write(f"**ê°’:** {value}")
                        st.write(f"**í‰ê°€:** {reason}")

with tab2:
    st.header("ğŸ† ì „ì²´ ì¢…ëª© ë­í‚¹")
    
    analyses = load_analyses()
    
    if not analyses:
        st.info("ì•„ì§ ë¶„ì„ëœ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¢…ëª©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”!")
    else:
        # Create ranking list
        ranking_data = []
        for ticker, data in analyses.items():
            analysis = data['data']
            ranking_data.append({
                'ìˆœìœ„': 0,
                'ì¢…ëª©ëª…': analysis.get('company_name', ticker),
                'í‹°ì»¤': analysis.get('ticker', ticker),
                'ì´ì ': analysis.get('total_score', 0),
                'ë¶„ì„ì¼': datetime.fromisoformat(data['timestamp']).strftime('%Y-%m-%d')
            })
        
        # Sort by total score
        ranking_data.sort(key=lambda x: x['ì´ì '], reverse=True)
        
        # Add ranking
        for i, item in enumerate(ranking_data):
            item['ìˆœìœ„'] = i + 1
        
        # Display ranking table
        st.dataframe(
            ranking_data,
            use_container_width=True,
            hide_index=True
        )
        
        # Top 3 highlight
        if len(ranking_data) >= 3:
            st.markdown("---")
            st.subheader("ğŸ¥‡ Top 3 ì¢…ëª©")
            cols = st.columns(3)
            
            for i, col in enumerate(cols[:3]):
                with col:
                    item = ranking_data[i]
                    st.metric(
                        f"#{i+1} {item['ì¢…ëª©ëª…']}",
                        f"{item['ì´ì ']}ì ",
                        f"ë¶„ì„ì¼: {item['ë¶„ì„ì¼']}"
                    )

# Footer
st.markdown("---")
st.caption("âš¡ Powered by Perplexity AI | ë°ì´í„°ëŠ” ìµœëŒ€ 7ì¼ê°„ ìºì‹œë©ë‹ˆë‹¤.")
